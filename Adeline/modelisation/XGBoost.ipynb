{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sweetviz as sv\n",
    "import missingno as msno\n",
    "import time \n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "from xgboost import XGBClassifier\n",
    "import requests\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6363/2889706020.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(\"/home/apprenant/Documents/DATA/loan_project/SBAnational.csv\")\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"/home/apprenant/Documents/DATA/loan_project/SBAnational.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ApprovalFY'] = df['ApprovalFY'].replace('A', '', regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6363/2501809618.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df[col] = df[col].str.replace(\"$\", \"\")\n"
     ]
    }
   ],
   "source": [
    "columns_to_transform_to_int = [\"DisbursementGross\",\"BalanceGross\",\"ChgOffPrinGr\",\"GrAppv\",\"SBA_Appv\"]\n",
    "\n",
    "\n",
    "for col in columns_to_transform_to_int:\n",
    "    df[col] = df[col].str.replace(\"$\", \"\")\n",
    "    df[col] = df[col].str.replace(\",\", \"\")\n",
    "    df[col] = df[col].astype(float)\n",
    "    \n",
    "\n",
    "df['Term'] = df['Term'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    784313\n",
       "Y    110335\n",
       "C       758\n",
       "S       603\n",
       "A       497\n",
       "R        75\n",
       "1         1\n",
       "Name: LowDoc, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LowDoc'] = df['LowDoc'].replace({'0': 'N'})\n",
    "df['LowDoc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    677890\n",
       "Y    216681\n",
       "1        23\n",
       "R        14\n",
       "`        11\n",
       "2         6\n",
       "C         2\n",
       ",         1\n",
       "3         1\n",
       "7         1\n",
       "A         1\n",
       "5         1\n",
       ".         1\n",
       "4         1\n",
       "-         1\n",
       "Q         1\n",
       "Name: RevLineCr, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RevLineCr'] = df['RevLineCr'].replace({'0': 'N', 'T':'Y'})\n",
    "df['RevLineCr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    677890\n",
       "Y    216681\n",
       "Name: RevLineCr, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['RevLineCr'].isin(['N','Y'])]\n",
    "df['RevLineCr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                                                                       199739\n",
       "Retail trade                                                                126783\n",
       "Other services (except public administration)                                72381\n",
       "Professional, scientific, and technical services                             67948\n",
       "Manufacturing                                                                67728\n",
       "Accommodation and food services                                              67474\n",
       "Construction                                                                 66408\n",
       "Health care and social assistance                                            55108\n",
       "Wholesale trade                                                              48555\n",
       "Administrative and support and waste management and remediation services     32609\n",
       " Transportation and warehousing                                              20287\n",
       "Arts, entertainment, and recreation                                          14597\n",
       "Real estate and rental and leasing                                           13599\n",
       "Information                                                                  11333\n",
       "Finance and insurance                                                         9486\n",
       "Agriculture, forestry, fishing and hunting                                    8932\n",
       "Educational services                                                          6414\n",
       "Transportation and warehousing                                                2207\n",
       "Mining, quarrying, and oil and gas extraction                                 1842\n",
       "Utilities                                                                      657\n",
       "Management of companies and enterprises                                        257\n",
       "Public administration                                                          227\n",
       "Name: Categorie_NAICS, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionnaire =  {\"11\":\"Agriculture, forestry, fishing and hunting\",\"72\":\"Accommodation and food services\",\"21\":\"Mining, quarrying, and oil and gas extraction\",\"22\":\n",
    "\"Utilities\",\"23\":\"Construction\",\"31\":\"Manufacturing\",\"32\":\"Manufacturing\",\"33\":\"Manufacturing\",\"42\":\"Wholesale trade\",\"44\":\"Retail trade\",\"45\":\"Retail trade\",\"48\":\" Transportation and warehousing\", \"49\":\"Transportation and warehousing\", \"51\":\"Information\",\"52\":\"Finance and insurance\", \"53\":\"Real estate and rental and leasing\",\"54\":\"Professional, scientific, and technical services\",\"55\":\"Management of companies and enterprises\",\"56\":\"Administrative and support and waste management and remediation services\",\"61\":\"Educational services\",\"62\":\"Health care and social assistance\",\"71\":\"Arts, entertainment, and recreation\",\"81\":\"Other services (except public administration)\", \"92\": \"Public administration\", \"0\" : \"Other\"}\n",
    "\n",
    "df['NAICS'] = df['NAICS'].astype(str).str[:2]\n",
    "\n",
    "df[\"Categorie_NAICS\"] = df[\"NAICS\"].map(dictionnaire)\n",
    "\n",
    "# df.Categorie.value_counts(dropna=False)\n",
    "\n",
    "df[\"Categorie_NAICS\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['LoanNr_ChkDgt', 'Name', 'City', 'Zip', 'Bank', 'BankState', 'ApprovalDate', 'RetainedJob','ChgOffDate', 'DisbursementDate', 'DisbursementGross', 'BalanceGross', 'SBA_Appv', 'ChgOffPrinGr']\n",
    "df_cleaned = df.copy()\n",
    "df_cleaned.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.dropna(subset=['MIS_Status'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_cleaned.MIS_Status\n",
    "X = df_cleaned.drop(columns=['MIS_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>ApprovalFY</th>\n",
       "      <th>Term</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>Categorie_NAICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209094</th>\n",
       "      <td>IL</td>\n",
       "      <td>31</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State NAICS  ApprovalFY  Term  NoEmp  NewExist  CreateJob  \\\n",
       "209094    IL    31        2007    12      1       2.0          0   \n",
       "\n",
       "        FranchiseCode  UrbanRural RevLineCr LowDoc    GrAppv Categorie_NAICS  \n",
       "209094              0           1         Y      N  350000.0   Manufacturing  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les hyperparamètres les plus importants pour XGBoost Classifier sont :\n",
    "\n",
    "n_estimators : le nombre d'arbres de décision dans le modèle\n",
    "learning_rate : le taux d'apprentissage utilisé pour mettre à jour les poids des modèles\n",
    "max_depth : la profondeur maximale de chaque arbre de décision\n",
    "subsample : la proportion d'échantillons utilisés pour construire chaque arbre\n",
    "colsample_bytree : la proportion de colonnes utilisées pour construire chaque arbre\n",
    "gamma : un paramètre qui régule la complexité de chaque arbre.\n",
    "reg_alpha : la régularisation L1 sur les poids\n",
    "reg_lambda : la régularisation L2 sur les poids.\n",
    "scale_pos_weight : pour gérer les déséquilibres de classe\n",
    "objective : choisir l'objectif de la régression, logistique pour la classification binaire, softmax pour la classification multi-classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector, ColumnTransformer, make_column_transformer\n",
    "# sklearn.compose: The sklearn.compose module is a submodule of the sklearn library for machine learning in Python. It provides functions for creating complex preprocessing and modeling pipelines.\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,PolynomialFeatures,RobustScaler\n",
    "#sklearn.preprocessing: The sklearn.preprocessing module is a submodule of the sklearn library that provides functions for preprocessing data, such as scaling and normalizing features, imputing missing values, and encoding categorical variables.\n",
    "from sklearn.linear_model import Ridge,LinearRegression,Lasso, ElasticNet\n",
    "# sklearn.linear_model: The sklearn.linear_model module is a submodule of the sklearn library that provides functions for fitting linear models for regression and classification.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# sklearn.pipeline: The sklearn.pipeline module is a submodule of the sklearn library that provides functions for creating and working with pipelines of transformers and models.\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,learning_curve, RandomizedSearchCV, cross_val_score, KFold\n",
    "# sklearn.model_selection: The sklearn.model_selection module is a submodule of the sklearn library that provides functions for splitting data into training and test sets, evaluating models using cross-validation, and hyperparameter tuning.\n",
    "from sklearn.dummy import DummyRegressor\n",
    "# sklearn.dummy: The sklearn.dummy module is a submodule of the sklearn library that provides simple dummy models for regression and classification.\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "def make_pipeline_to_ML(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.9, random_state=42)\n",
    "    numerical_features = make_column_selector(dtype_include=np.number)\n",
    "    categorical_features = make_column_selector(dtype_exclude= np.number)\n",
    "    numerical_pipeline = make_pipeline(SimpleImputer(strategy='mean'),StandardScaler(with_mean=False))\n",
    "    categorical_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'),OneHotEncoder(handle_unknown='ignore'))\n",
    "    preprocessor = make_column_transformer((numerical_pipeline, numerical_features),\n",
    "                                    (categorical_pipeline, categorical_features)\n",
    "                                    )\n",
    "    return preprocessor, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "preprocessor, X_train, X_test, y_train, y_test = make_pipeline_to_ML(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 803323 entries, 209094 to 122762\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   State            803314 non-null  object \n",
      " 1   NAICS            803323 non-null  object \n",
      " 2   ApprovalFY       803323 non-null  int64  \n",
      " 3   Term             803323 non-null  int64  \n",
      " 4   NoEmp            803323 non-null  int64  \n",
      " 5   NewExist         803211 non-null  float64\n",
      " 6   CreateJob        803323 non-null  int64  \n",
      " 7   FranchiseCode    803323 non-null  int64  \n",
      " 8   UrbanRural       803323 non-null  int64  \n",
      " 9   RevLineCr        803323 non-null  object \n",
      " 10  LowDoc           801038 non-null  object \n",
      " 11  GrAppv           803323 non-null  float64\n",
      " 12  Categorie_NAICS  803323 non-null  object \n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 85.8+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209094     P I F\n",
       "249452     P I F\n",
       "869307     P I F\n",
       "91777      P I F\n",
       "807410     P I F\n",
       "           ...  \n",
       "260353     P I F\n",
       "367137     P I F\n",
       "132769     P I F\n",
       "673408     P I F\n",
       "122762    CHGOFF\n",
       "Name: MIS_Status, Length: 803323, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoder = le.fit_transform(y_train)\n",
    "y_test_encoder = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P I F', 'P I F', 'P I F', ..., 'P I F', 'P I F', 'CHGOFF'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_data = le.inverse_transform(y_train_encoder)\n",
    "decoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = make_pipeline(preprocessor, XGBClassifier(\n",
    "    objective= 'binary:logistic',    tree_method = 'hist', random_state =42, n_jobs=-1\n",
    "))\n",
    "param_grid = {'xgbclassifier__max_depth': [10],\n",
    "            'xgbclassifier__n_estimators': [200],\n",
    "              'xgbclassifier__learning_rate': [ 0.2],\n",
    "            \n",
    "             'xgbclassifier__colsample_bytree' : [ 0.7],\n",
    "            'xgbclassifier__scale_pos_weight' : [ 1]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search2 = make_pipeline(preprocessor, GridSearchCV(\n",
    "#     estimator=estimator,\n",
    "#     param_grid=param_grid,\n",
    "\n",
    "\n",
    " \n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search2 = GridSearchCV(estimator,param_grid,cv=5 , verbose=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=200, xgbclassifier__scale_pos_weight=1;, score=nan total time=   7.2s\n",
      "[CV 2/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=200, xgbclassifier__scale_pos_weight=1;, score=nan total time=   7.3s\n",
      "[CV 3/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=200, xgbclassifier__scale_pos_weight=1;, score=nan total time=   7.6s\n",
      "[CV 4/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=200, xgbclassifier__scale_pos_weight=1;, score=nan total time=   7.3s\n",
      "[CV 5/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=200, xgbclassifier__scale_pos_weight=1;, score=nan total time=   7.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/apprenant/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/apprenant/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/sklearn/pipeline.py\", line 406, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/home/apprenant/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/home/apprenant/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1466, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['CHGOFF' 'P I F']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grid_bost  \u001b[39m=\u001b[39m grid_search2\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1388\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    854\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/apprenant/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/apprenant/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/sklearn/pipeline.py\", line 406, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/home/apprenant/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/home/apprenant/miniconda3/envs/data_analyse_env/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1466, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['CHGOFF' 'P I F']\n"
     ]
    }
   ],
   "source": [
    "grid_bost  = grid_search2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleurs paramètres sont : {'xgbclassifier__colsample_bytree': 0.7, 'xgbclassifier__learning_rate': 0.2, 'xgbclassifier__max_depth': 10, 'xgbclassifier__n_estimators': 200, 'xgbclassifier__scale_pos_weight': 1}\n",
      "le meilleurs score sont : 0.9490989314566749\n"
     ]
    }
   ],
   "source": [
    "print(\"les meilleurs paramètres sont :\",grid_bost.best_params_)\n",
    "print(\"le meilleurs score sont :\",grid_bost.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {0.9616903785899321}\n",
      "f1_SCORE_WEIGHTED: {0.9614010703305332}\n",
      "f1_SCORE_MACRO: {0.9331069402909564}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = grid_search2.predict(X_train)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print (\"Accuracy:\", {metrics.accuracy_score(y_train, y_pred)})\n",
    "print (\"f1_SCORE_WEIGHTED:\", {metrics.f1_score(y_train, y_pred, average='weighted')})\n",
    "print (\"f1_SCORE_MACRO:\", {metrics.f1_score(y_train, y_pred, average='macro')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {0.9497641694394963}\n",
      "f1_SCORE_WEIGHTED: {0.9493551081729162}\n",
      "f1_SCORE_MACRO: {0.9118852256039505}\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = grid_search2.predict(X_test)\n",
    "print (\"Accuracy:\", {metrics.accuracy_score(y_test, y_pred2)})\n",
    "print (\"f1_SCORE_WEIGHTED:\", {metrics.f1_score(y_test, y_pred2, average='weighted')})\n",
    "print (\"f1_SCORE_MACRO:\", {metrics.f1_score(y_test, y_pred2, average='macro')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89259"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89259"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89    141760\n",
      "           1       0.97      0.98      0.98    661563\n",
      "\n",
      "    accuracy                           0.96    803323\n",
      "   macro avg       0.94      0.93      0.93    803323\n",
      "weighted avg       0.96      0.96      0.96    803323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85     15684\n",
      "           1       0.97      0.97      0.97     73575\n",
      "\n",
      "    accuracy                           0.95     89259\n",
      "   macro avg       0.92      0.91      0.91     89259\n",
      "weighted avg       0.95      0.95      0.95     89259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = make_pipeline(preprocessor, XGBClassifier(n_estimators=500, \n",
    "                            learning_rate=0.1, \n",
    "                            max_depth=5, \n",
    "                            subsample=0.8, \n",
    "                            colsample_bytree=0.8, \n",
    "                            gamma=0, \n",
    "                            reg_alpha=0, \n",
    "                            reg_lambda=1,\n",
    "                            scale_pos_weight=1,\n",
    "                            tree_method=\"hist\",\n",
    "                            objective='binary:logistic'))\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les données de test\n",
    "y_pred3 = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {0.94752349903091}\n",
      "f1_SCORE_WEIGHTED: {0.9469065243927655}\n",
      "f1_SCORE_MACRO: {0.9073086543519269}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Accuracy:\", {metrics.accuracy_score(y_test, y_pred3)})\n",
    "print (\"f1_SCORE_WEIGHTED:\", {metrics.f1_score(y_test, y_pred3, average='weighted')})\n",
    "print (\"f1_SCORE_MACRO:\", {metrics.f1_score(y_test, y_pred3, average='macro')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85     15684\n",
      "           1       0.96      0.97      0.97     73575\n",
      "\n",
      "    accuracy                           0.95     89259\n",
      "   macro avg       0.92      0.90      0.91     89259\n",
      "weighted avg       0.95      0.95      0.95     89259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__gamma=0.5, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=100, xgbclassifier__reg_alpha=1, xgbclassifier__reg_lambda=1, xgbclassifier__scale_pos_weight=1, xgbclassifier__subsample=0.8;, score=0.948 total time= 1.4min\n",
      "[CV 5/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__gamma=0.5, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=100, xgbclassifier__reg_alpha=1, xgbclassifier__reg_lambda=1, xgbclassifier__scale_pos_weight=1, xgbclassifier__subsample=0.8;, score=0.949 total time= 1.4min\n",
      "[CV 2/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__gamma=0.5, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=100, xgbclassifier__reg_alpha=1, xgbclassifier__reg_lambda=1, xgbclassifier__scale_pos_weight=1, xgbclassifier__subsample=0.8;, score=0.949 total time= 1.4min\n",
      "[CV 4/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__gamma=0.5, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=100, xgbclassifier__reg_alpha=1, xgbclassifier__reg_lambda=1, xgbclassifier__scale_pos_weight=1, xgbclassifier__subsample=0.8;, score=0.949 total time= 1.4min\n",
      "[CV 3/5] END xgbclassifier__colsample_bytree=0.7, xgbclassifier__gamma=0.5, xgbclassifier__learning_rate=0.2, xgbclassifier__max_depth=10, xgbclassifier__n_estimators=100, xgbclassifier__reg_alpha=1, xgbclassifier__reg_lambda=1, xgbclassifier__scale_pos_weight=1, xgbclassifier__subsample=0.8;, score=0.948 total time= 1.4min\n",
      "Meilleurs hyperparamètres :  {'xgbclassifier__colsample_bytree': 0.7, 'xgbclassifier__gamma': 0.5, 'xgbclassifier__learning_rate': 0.2, 'xgbclassifier__max_depth': 10, 'xgbclassifier__n_estimators': 100, 'xgbclassifier__reg_alpha': 1, 'xgbclassifier__reg_lambda': 1, 'xgbclassifier__scale_pos_weight': 1, 'xgbclassifier__subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir les valeurs des hyperparamètres à tester\n",
    "param_grid = {'xgbclassifier__n_estimators': [100],\n",
    "              'xgbclassifier__learning_rate': [0.2],\n",
    "              'xgbclassifier__max_depth': [10],\n",
    "              'xgbclassifier__subsample': [ 0.8],\n",
    "              'xgbclassifier__colsample_bytree': [ 0.7],\n",
    "              'xgbclassifier__gamma': [0.5],\n",
    "             'xgbclassifier__reg_alpha': [ 1],\n",
    "             'xgbclassifier__reg_lambda': [ 1],\n",
    "          'xgbclassifier__scale_pos_weight': [1],\n",
    "             }\n",
    "\n",
    "# Initialiser le modèle\n",
    "xgb_clf = make_pipeline(preprocessor,xgb.XGBClassifier(objective= 'binary:logistic',    tree_method = 'hist'))\n",
    "\n",
    "# Initialiser la recherche d'hyperparamètres\n",
    "grid_search = GridSearchCV(xgb_clf, param_grid, cv=5, n_jobs=-1,verbose=4)\n",
    "\n",
    "# Entraîner le modèle en utilisant la recherche d'hyperparamètres\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres\n",
    "print(\"Meilleurs hyperparamètres : \", grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres :  0.9486034893154385\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs hyperparamètres : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: {0.94947288228638}\n",
      "f1_SCORE_WEIGHTED: {0.9489794507940464}\n",
      "f1_SCORE_MACRO: {0.9110945137612918}\n"
     ]
    }
   ],
   "source": [
    "y_pred4 = grid_search.predict(X_test)\n",
    "print (\"Accuracy:\", {metrics.accuracy_score(y_test, y_pred4)})\n",
    "print (\"f1_SCORE_WEIGHTED:\", {metrics.f1_score(y_test, y_pred4, average='weighted')})\n",
    "print (\"f1_SCORE_MACRO:\", {metrics.f1_score(y_test, y_pred4, average='macro')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analyse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efb016019911489f5a03966f4d1632bb4674bdc6f12f4d95624e206dc03ec67a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
